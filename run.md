﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿# Usage Guide------------------## PrerequisitesThe major libraries  to run the code are as follow.- [Multi-core LIBLINEAR][liblinear]- [scikit-learn][sklearn]- [OpenCV library][opencv]- [VLFeat ][vlfeat]- [Temporal Segment Networks (TSN)][tsn]- [Motion Keypoint Trajectory (MKT)][mkt]- [openSMILE][opensmile]## Feature extraction- Calculate vectors of the ConvNets feature according to the [URL][tsn].- Calculate vectors of the MKT feature according to the [URL][mkt].- Calculate vectors of the  EmoBase10 feature according to the [URL][opensmile].## Data PreparationDownload the testing vectors of EIMT16 from [Baiduyun][baidu], and the password is ``62h6``. Then, extract the downloaded file to the directory ``./data/npy``.## Testing Provided ModelTo evaluate the model trained on EIMT16, run```python3 EIMT16-test.py```## Training ModelTo train the model on EIMT16, run```python3 EIMT16-train.py --respath <path of features>```## ReferenceIf you find the code useful, please cite the following paper:```@article{Yi2018Multi,  title={Multi-modal learning for affective content analysis in movies},  author={Yi, Yun and Wang, Hanli},  journal={Multimedia Tools & Applications},  year={in press 2018},  doi={10.1007/s11042-018-5662-9},  url={https://doi.org/10.1007/s11042-018-5662-9}}``` [liblinear]:https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/multicore-liblinear/[sklearn]:http://scikit-learn.org/stable/index.html[tsn]:https://github.com/yjxiong/temporal-segment-networks[opensmile]:https://audeering.com/technology/opensmile/[mkt]:https://mic.tongji.edu.cn/51/43/c9778a86339/page.htm[baidu]:https://pan.baidu.com/s/1widuPSSdo6xy7s3K1TMRPg[vlfeat]:http://www.vlfeat.org/[opencv]:https://opencv.org/